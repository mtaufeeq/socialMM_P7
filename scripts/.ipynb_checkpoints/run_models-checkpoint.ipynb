{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import train_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a context aware model \n",
    "\n",
    "Use probabilities from classifier, LDA topics and metadata / context data. Goal is to build an interpretable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet Text', 'Tweet Datetime', 'Tweet Id', 'User Id', 'User Name',\n",
      "       'User Location', 'Tweet Coordinates', 'Place Info', 'Country',\n",
      "       'Hashtags', 'Retweets', 'Favorites', 'Language', 'Source',\n",
      "       'Replied Tweet Id', 'Replied Tweet User Id', 'month', 'ground_truth',\n",
      "       'ID', 'folds', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/stack_files/balanced_pro_n_anti_mask_df_v3.csv\")\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 1, 3]\n",
      "(12008, 24)\n",
      "Results obtained on fold: 4\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.668709     0.713120   0.68775     0.690914      0.690692\n",
      "recall        0.756436     0.617677   0.68775     0.687056      0.687750\n",
      "f1-score      0.709872     0.661976   0.68775     0.685924      0.686163\n",
      "support    2020.000000  1980.000000   0.68775  4000.000000   4000.000000\n",
      "(12001, 24)\n",
      "Results obtained on fold: 2\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.669319     0.750143  0.704517     0.709731      0.710810\n",
      "recall        0.776410     0.636364  0.704517     0.706387      0.704517\n",
      "f1-score      0.718898     0.688585  0.704517     0.703742      0.703337\n",
      "support    1950.000000  2057.000000  0.704517  4007.000000   4007.000000\n",
      "(12005, 24)\n",
      "Results obtained on fold: 1\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.679940     0.678034  0.678991     0.678987      0.678990\n",
      "recall        0.680279     0.677694  0.678991     0.678987      0.678991\n",
      "f1-score      0.680110     0.677864  0.678991     0.678987      0.678990\n",
      "support    2008.000000  1995.000000  0.678991  4003.000000   4003.000000\n",
      "(12010, 24)\n",
      "Results obtained on fold: 3\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.683761     0.686575  0.685093     0.685168      0.685144\n",
      "recall        0.708313     0.661069  0.685093     0.684691      0.685093\n",
      "f1-score      0.695820     0.673581  0.685093     0.684700      0.684890\n",
      "support    2033.000000  1965.000000  0.685093  3998.000000   3998.000000\n"
     ]
    }
   ],
   "source": [
    "context_features = ['Retweets', 'Favorites', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound']\n",
    "\n",
    "model_type = \"XGB\"\n",
    "res_df = train_models.train_n_cv_valid_models(df, context_features, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on BERT Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3201, 12021)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on TF-IDF features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet Text', 'Tweet Datetime', 'Tweet Id', 'User Id', 'User Name',\n",
      "       'User Location', 'Tweet Coordinates', 'Place Info', 'Country',\n",
      "       'Hashtags', 'Retweets', 'Favorites', 'Language', 'Source',\n",
      "       'Replied Tweet Id', 'Replied Tweet User Id', 'month', 'ground_truth',\n",
      "       'ID', 'folds', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound'],\n",
      "      dtype='object')\n",
      "(3201, 12019)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/stack_files/balanced_pro_n_anti_mask_df_v3.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "TF_IDF_df = pd.read_csv(\"../data/stack_files/balanced_pro_n_anti_mask_TF_IDF_df_v4.csv\")\n",
    "print(TF_IDF_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df[[\"ground_truth\", \"folds\", \"ID\"]], TF_IDF_df, on=[\"ID\"], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201, 12021)\n",
      "[2, 3, 1, 4]\n",
      "(2400, 12021)\n",
      "Results obtained on fold: 2\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    407.0  394.0       1.0      801.0         801.0\n",
      "(2401, 12021)\n",
      "Results obtained on fold: 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    1.000000    0.997462   0.99875    0.998731      0.998753\n",
      "recall       0.997543    1.000000   0.99875    0.998771      0.998750\n",
      "f1-score     0.998770    0.998729   0.99875    0.998750      0.998750\n",
      "support    407.000000  393.000000   0.99875  800.000000    800.000000\n",
      "(2401, 12021)\n",
      "Results obtained on fold: 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.995157    0.994832     0.995    0.994995         0.995\n",
      "recall       0.995157    0.994832     0.995    0.994995         0.995\n",
      "f1-score     0.995157    0.994832     0.995    0.994995         0.995\n",
      "support    413.000000  387.000000     0.995  800.000000       800.000\n",
      "(2401, 12021)\n",
      "Results obtained on fold: 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    1.000000    0.997487   0.99875    0.998744      0.998753\n",
      "recall       0.997519    1.000000   0.99875    0.998759      0.998750\n",
      "f1-score     0.998758    0.998742   0.99875    0.998750      0.998750\n",
      "support    403.000000  397.000000   0.99875  800.000000    800.000000\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)\n",
    "\n",
    "TF_IDF_features = TF_IDF_df.columns.tolist()[:-1]\n",
    "\n",
    "model_type = \"XGB\"\n",
    "res_df = train_models.train_n_cv_valid_models(merged_df, TF_IDF_features, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE and other visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA  for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet Text', 'Tweet Datetime', 'Tweet Id', 'User Id', 'User Name',\n",
      "       'User Location', 'Tweet Coordinates', 'Place Info', 'Country',\n",
      "       'Hashtags', 'Retweets', 'Favorites', 'Language', 'Source',\n",
      "       'Replied Tweet Id', 'Replied Tweet User Id', 'month', 'ground_truth',\n",
      "       'ID', 'folds', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound'],\n",
      "      dtype='object')\n",
      "(3201, 12019)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/stack_files/balanced_pro_n_anti_mask_df_v3.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "TF_IDF_df = pd.read_csv(\"../data/stack_files/balanced_pro_n_anti_mask_TF_IDF_df_v4.csv\")\n",
    "print(TF_IDF_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df[[\"ground_truth\", \"folds\", \"ID\"]], TF_IDF_df, on=[\"ID\"], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201, 12021)\n",
      "[2, 3, 1, 4]\n",
      "(2400, 12021)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-02240645c35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"XGB\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_n_cv_valid_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_IDF_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/usf_courses/Fall20/socialMM_P7/scripts/train_models.py\u001b[0m in \u001b[0;36mtrain_n_cv_valid_models\u001b[0;34m(df, features, flag)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# run experiment for classification with BERT features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"XGB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ground_truth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/usf_courses/Fall20/socialMM_P7/scripts/model_.py\u001b[0m in \u001b[0;36mxgboost_classifier\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mxgboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# , max_depth=32 # for pain detection usnig scale_pos_weight = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/socialMM/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    832\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/socialMM/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/socialMM/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/socialMM/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)\n",
    "\n",
    "TF_IDF_features = TF_IDF_df.columns.tolist()[:-1]\n",
    "\n",
    "model_type = \"XGB\"\n",
    "\n",
    "\n",
    "res_df = train_models.train_n_cv_valid_LDA(merged_df, TF_IDF_features, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialMM",
   "language": "python",
   "name": "socialmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
